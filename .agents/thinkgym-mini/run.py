#!/usr/bin/env python3
import argparse
import json
import re
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List


PROMPT_DIR = Path(__file__).parent / "prompts"
SHORT_NOTE_THRESHOLD = 20
STOPWORDS = {
    "ì €ëŠ”",
    "ë‚˜ëŠ”",
    "ì œê°€",
    "ìš°ë¦¬",
    "ê·¸ë¦¬ê³ ",
    "í•˜ì§€ë§Œ",
    "ê·¸ëŸ¬ë‚˜",
    "ë‹¤ë§Œ",
    "ì´ê²ƒ",
    "ê·¸ê²ƒ",
    "ì£¼ì¥",
}


@dataclass
class RoundResult:
    round_no: int
    topic: str
    pro_statement: str
    con_statement: str
    user_note: str
    structure_feedback: Dict[str, object]
    summary_report: str
    next_question: str


def load_prompt(name: str) -> str:
    path = PROMPT_DIR / name
    return path.read_text(encoding="utf-8").strip()


def render_template(text: str, variables: Dict[str, str]) -> str:
    rendered = text
    for key, value in variables.items():
        rendered = rendered.replace("{{" + key + "}}", value)
    return rendered


def sentence_count(text: str) -> int:
    return len(split_sentences(text))


def split_sentences(text: str) -> List[str]:
    # Split only on likely sentence boundaries: punctuation + whitespace.
    return [p.strip() for p in re.split(r"(?<=[.!?])\s+(?=[\"'\\(\\[]?[ê°€-í£A-Za-z0-9])", text.strip()) if p.strip()]


def ensure_three_sentences(text: str, agent_name: str) -> None:
    if sentence_count(text) != 3:
        raise ValueError(f"{agent_name} ì¶œë ¥ì€ ì •í™•íˆ 3ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤: {text}")


def extract_keywords(text: str) -> List[str]:
    words = re.findall(r"[ê°€-í£A-Za-z0-9]{2,}", text)
    seen = set()
    keywords = []
    for word in words:
        w = word.lower()
        if w not in seen:
            seen.add(w)
            keywords.append(word)
    return keywords


def extract_salient_keywords(text: str) -> List[str]:
    return [w for w in extract_keywords(text) if w.lower() not in STOPWORDS]


def validate_con_first_sentence(con_text: str, pro_text: str) -> None:
    sentences = split_sentences(con_text)
    if not sentences:
        raise ValueError("Con ì¶œë ¥ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    first = sentences[0]
    pro_keywords = extract_salient_keywords(pro_text)
    if not pro_keywords:
        return
    if not any(keyword in first for keyword in pro_keywords[:5]):
        raise ValueError("Con ì²« ë¬¸ì¥ì´ Pro ë°œì–¸ í‚¤ì›Œë“œë¥¼ ì§ì ‘ ì°¸ì¡°í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def validate_con_topic_relevance(con_text: str, topic: str) -> None:
    topic_keywords = extract_salient_keywords(topic)
    if not topic_keywords:
        return
    if not any(keyword in con_text for keyword in topic_keywords[:5]):
        raise ValueError("Con ì¶œë ¥ì´ ì£¼ì œ í‚¤ì›Œë“œë¥¼ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def validate_structure_json(data: Dict[str, object], user_note: str) -> None:
    expected_keys = [
        "claim",
        "reasons",
        "assumptions",
        "counterpoints",
        "missing_info",
        "next_revision",
    ]
    if list(data.keys()) != expected_keys:
        raise ValueError("Structure JSON í‚¤ ìˆœì„œ/êµ¬ì¡°ê°€ ìŠ¤í‚¤ë§ˆì™€ ë‹¤ë¦…ë‹ˆë‹¤.")

    for key in expected_keys:
        if key not in data:
            raise ValueError(f"Structure JSON ëˆ„ë½ í‚¤: {key}")

    for key in ["reasons", "assumptions", "counterpoints", "missing_info"]:
        if not isinstance(data[key], list):
            raise ValueError(f"{key}ëŠ” ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    if not isinstance(data["claim"], str) or not isinstance(data["next_revision"], str):
        raise ValueError("claim/next_revisionì€ ë¬¸ìì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    compact = json.dumps(data, ensure_ascii=False)
    if "\n" in compact or "\r" in compact:
        raise ValueError("Structure JSON ê°’ì— ì¤„ë°”ê¿ˆì´ ìˆìœ¼ë©´ ì•ˆ ë©ë‹ˆë‹¤.")

    if len(user_note.strip()) < SHORT_NOTE_THRESHOLD:
        if data["claim"] != "ì…ì¥ì´ ì•„ì§ ëª…í™•íˆ ì •ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.":
            raise ValueError("ì§§ì€ user_note ê·œì¹™ claim ë¶ˆì¼ì¹˜")
        if data["reasons"] != [] or data["assumptions"] != [] or data["counterpoints"] != []:
            raise ValueError("ì§§ì€ user_note ê·œì¹™ ë°°ì—´ì´ ë¹„ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
        expected_missing = ["ì£¼ì¥ì„ 1ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”", "ê·¼ê±°ë¥¼ ìµœì†Œ 2ê°œ ì œì‹œí•˜ì„¸ìš”"]
        if data["missing_info"] != expected_missing:
            raise ValueError("ì§§ì€ user_note ê·œì¹™ missing_info ë¶ˆì¼ì¹˜")
        expected_next = (
            "ì£¼ì¥ì„ 1ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ì‹­ì‹œì˜¤. ê·¸ ì£¼ì¥ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê·¼ê±° 2ê°€ì§€ë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤. "
            "ë°˜ëŒ€ ì˜ê²¬ì— ëŒ€í•œ ëŒ€ë¹„ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤."
        )
        if data["next_revision"] != expected_next:
            raise ValueError("ì§§ì€ user_note ê·œì¹™ next_revision ë¶ˆì¼ì¹˜")
    else:
        if not 2 <= len(data["reasons"]) <= 3:
            raise ValueError("reasonsëŠ” 2~3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.")
        if not 1 <= len(data["assumptions"]) <= 2:
            raise ValueError("assumptionsëŠ” 1~2ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.")
        if not 1 <= len(data["counterpoints"]) <= 2:
            raise ValueError("counterpointsëŠ” 1~2ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.")
        if not 1 <= len(data["missing_info"]) <= 2:
            raise ValueError("missing_infoëŠ” 1~2ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.")
        if sentence_count(data["next_revision"]) != 3:
            raise ValueError("next_revisionì€ ì •í™•íˆ 3ë¬¸ì¥ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")


def parse_structure_json(text: str, user_note: str) -> Dict[str, object]:
    data = json.loads(text)
    validate_structure_json(data, user_note)
    return data


def extract_section(report: str, section_title: str, next_section_title: str) -> str:
    start = report.find(section_title)
    if start < 0:
        return ""
    if not next_section_title:
        return report[start + len(section_title):].strip()
    end = report.find(next_section_title, start + len(section_title))
    if end < 0:
        return report[start + len(section_title):].strip()
    return report[start + len(section_title):end].strip()


def validate_summary_report(report: str) -> None:
    required_headers = [
        "# ğŸ“ ThinkGym ì„¸ì…˜ ë¦¬í¬íŠ¸",
        "## 1. ì˜¤ëŠ˜ì˜ ì§ˆë¬¸",
        "## 2. ì°¬ë°˜ í•µì‹¬ ìš”ì•½",
        "## 3. ì‚¬ìš©ìì˜ ì…ì¥",
        "## 4. ë…¼ë¦¬ êµ¬ì¡° ê°œì„  í¬ì¸íŠ¸",
        "## 5. ë‹¤ìŒ ë¼ìš´ë“œ ì¶”ì²œ ì§ˆë¬¸",
    ]
    for header in required_headers:
        if header not in report:
            raise ValueError(f"Summary ë¦¬í¬íŠ¸ í—¤ë” ëˆ„ë½: {header}")

    user_section = extract_section(report, "## 3. ì‚¬ìš©ìì˜ ì…ì¥", "## 4. ë…¼ë¦¬ êµ¬ì¡° ê°œì„  í¬ì¸íŠ¸")
    user_lines = [line.strip() for line in user_section.splitlines() if line.strip()]
    if len(user_lines) != 3:
        raise ValueError("ì‚¬ìš©ìì˜ ì…ì¥ ì„¹ì…˜ì€ ì •í™•íˆ 3ì¤„ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    improve_section = extract_section(report, "## 4. ë…¼ë¦¬ êµ¬ì¡° ê°œì„  í¬ì¸íŠ¸", "## 5. ë‹¤ìŒ ë¼ìš´ë“œ ì¶”ì²œ ì§ˆë¬¸")
    improve_lines = [line.strip() for line in improve_section.splitlines() if line.strip().startswith("-")]
    if len(improve_lines) != 3:
        raise ValueError("ë…¼ë¦¬ êµ¬ì¡° ê°œì„  í¬ì¸íŠ¸ëŠ” ì •í™•íˆ 3ê°œì—¬ì•¼ í•©ë‹ˆë‹¤.")

    next_q_section = extract_section(report, "## 5. ë‹¤ìŒ ë¼ìš´ë“œ ì¶”ì²œ ì§ˆë¬¸", "")
    next_lines = [line.strip() for line in next_q_section.splitlines() if line.strip()]
    if len(next_lines) != 1:
        raise ValueError("ë‹¤ìŒ ë¼ìš´ë“œ ì¶”ì²œ ì§ˆë¬¸ì€ ì •í™•íˆ 1ì¤„ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")


def make_debate_transcript(pro_text: str, con_text: str) -> str:
    return f"[ì°¬ì„±] {pro_text}\n[ë°˜ëŒ€] {con_text}"


def mock_pro(topic: str, user_note: str) -> str:
    context = "ì´ì „ ë¼ìš´ë“œ ì‚¬ìš©ì ë©”ëª¨ê°€ ìŸì ì„ êµ¬ì²´í™”" if user_note.strip() else "í•µì‹¬ ì§ˆë¬¸ì˜ ë°©í–¥ì„±"
    return (
        f"ì €ëŠ” '{topic}'ì— ì°¬ì„±í•˜ë©° ì´ ì„ íƒì´ ì¥ê¸°ì ìœ¼ë¡œ ë” ë†’ì€ ì˜ì‚¬ê²°ì • í’ˆì§ˆì„ ë§Œë“ ë‹¤ê³  ë´…ë‹ˆë‹¤. "
        f"ì²«ì§¸ {context}ì„ ê°•í™”í•˜ê³  ë‘˜ì§¸ ì‹¤í–‰ ê¸°ì¤€ì„ ëª…í™•íˆ í•´ íŒ€ì˜ í˜¼ì„ ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        "ë‹¤ë§Œ ë‹¨ê¸° ì„±ê³¼ ì••ë°•ì´ í° í™˜ê²½ì—ì„œëŠ” ì´ˆê¸° ë¹„ìš©ì´ ë¶€ë‹´ì´ë¼ëŠ” ë°˜ë¡ ì´ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )


def mock_con(topic: str, pro_statement: str) -> str:
    pro_keywords = extract_salient_keywords(pro_statement)
    keyword = pro_keywords[0] if pro_keywords else "í•µì‹¬ ê·¼ê±°"
    return (
        f"ì €ëŠ” '{topic}'ì— ë°˜ëŒ€í•˜ë©°, ì°¬ì„± ì¸¡ì˜ '{keyword}'ë§Œìœ¼ë¡œëŠ” ì •ì±… ì „í™˜ì˜ íƒ€ë‹¹ì„±ì„ ì¶©ë¶„íˆ ì…ì¦í•˜ê¸° ì–´ë µë‹¤ê³  ë´…ë‹ˆë‹¤. "
        "ì²«ì§¸ ì´ˆê¸° ë¹„ìš©ê³¼ ìš´ì˜ ë³µì¡ë„ê°€ ì»¤ì§€ê³  ë‘˜ì§¸ ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ ì±…ì„ê³¼ ë³µêµ¬ ê¸°ì¤€ì´ ë¶ˆëª…í™•í•´ ì‹¤ì œ ì„±ê³¼ê°€ ì•…í™”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        f"ë‹¤ë§Œ ì „ë©´ ë„ì… ëŒ€ì‹  ì œí•œëœ íŒŒì¼ëŸ¿ê³¼ ëª…í™•í•œ ì¤‘ë‹¨ ê¸°ì¤€ì„ ë¨¼ì € í•©ì˜í•œë‹¤ë©´ '{topic}'ì— ëŒ€í•´ ì¡°ê±´ë¶€ ë…¼ì˜ëŠ” ê°€ëŠ¥í•©ë‹ˆë‹¤."
    )


def mock_structure(topic: str, transcript: str, user_note: str) -> str:
    if len(user_note.strip()) < SHORT_NOTE_THRESHOLD:
        data = {
            "claim": "ì…ì¥ì´ ì•„ì§ ëª…í™•íˆ ì •ë¦¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
            "reasons": [],
            "assumptions": [],
            "counterpoints": [],
            "missing_info": ["ì£¼ì¥ì„ 1ë¬¸ì¥ìœ¼ë¡œ ëª…í™•íˆ ì‘ì„±í•˜ì„¸ìš”", "ê·¼ê±°ë¥¼ ìµœì†Œ 2ê°œ ì œì‹œí•˜ì„¸ìš”"],
            "next_revision": "ì£¼ì¥ì„ 1ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬í•˜ì‹­ì‹œì˜¤. ê·¸ ì£¼ì¥ì„ ë’·ë°›ì¹¨í•˜ëŠ” ê·¼ê±° 2ê°€ì§€ë¥¼ ì¶”ê°€í•˜ì‹­ì‹œì˜¤. ë°˜ëŒ€ ì˜ê²¬ì— ëŒ€í•œ ëŒ€ë¹„ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤.",
        }
    else:
        data = {
            "claim": f"ì‚¬ìš©ìëŠ” '{topic}'ì— ëŒ€í•´ ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì¡°ê±´ë¶€ ì°¬ì„± ì…ì¥ì„ ë³´ì…ë‹ˆë‹¤.",
            "reasons": [
                "ì˜ì‚¬ê²°ì • ê¸°ì¤€ì„ ëª…í™•íˆ í•´ì•¼ íŒ€ì˜ í˜¼ì„ ì´ ì¤„ì–´ë“ ë‹¤ê³  ë³´ì•˜ìŠµë‹ˆë‹¤.",
                "ë‹¨ê³„ì  ê²€ì¦ì„ í†µí•´ ì‹¤íŒ¨ ë¹„ìš©ì„ í†µì œí•  ìˆ˜ ìˆë‹¤ê³  íŒë‹¨í–ˆìŠµë‹ˆë‹¤.",
            ],
            "assumptions": ["íŒ€ì´ ê³µí†µ ì§€í‘œë¥¼ í•©ì˜í•˜ë©´ ì‹¤í–‰ ë§ˆì°°ì´ ì¤„ì–´ë“ ë‹¤ëŠ” ê°€ì •ì´ ìˆìŠµë‹ˆë‹¤."],
            "counterpoints": ["ì´ˆê¸° ë¦¬ì†ŒìŠ¤ ë¶€ì¡± ìƒí™©ì—ì„œëŠ” ì ì§„ì  ì‹¤í—˜ë„ ë¶€ë‹´ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."],
            "missing_info": ["ì‹¤í–‰ ìš°ì„ ìˆœìœ„ë¥¼ ì •í•˜ëŠ” ì •ëŸ‰ ê¸°ì¤€ì´ ì•„ì§ ì œì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."],
            "next_revision": "í•µì‹¬ ì£¼ì¥ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë” ì„ ëª…í•˜ê²Œ ê³ ì •í•˜ì„¸ìš”. ì‹¤í–‰ ê¸°ì¤€ì„ ìˆ˜ì¹˜ë¡œ ì œì‹œí•´ ì„¤ë“ë ¥ì„ ë†’ì´ì„¸ìš”. ë°˜ëŒ€ ìƒí™©ì—ì„œì˜ ëŒ€ì‘ ê³„íšì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ë¶™ì´ì„¸ìš”.",
        }
    return json.dumps(data, ensure_ascii=False)


def mock_summary(topic: str, pro_text: str, con_text: str, user_note: str, structure: Dict[str, object]) -> str:
    assumptions = structure.get("assumptions", [])
    counterpoints = structure.get("counterpoints", [])
    missing_info = structure.get("missing_info", [])

    assumption_point = assumptions[0] if assumptions else "ì…ì¥ ê°€ì •ì´ ì•„ì§ ì¶©ë¶„íˆ ëª…ì‹œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    counter_point = counterpoints[0] if counterpoints else "ë°˜ëŒ€ ë…¼ì ì„ ë¨¼ì € ì •ì˜í•˜ë©´ ë…¼ì˜ ê· í˜•ì´ ì¢‹ì•„ì§‘ë‹ˆë‹¤."
    missing_point = missing_info[0] if missing_info else "í•µì‹¬ ê·¼ê±°ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ ë³´ì™„í•˜ì„¸ìš”."

    user_line1 = "ì‚¬ìš©ìëŠ” í•µì‹¬ ì…ì¥ì„ ì •êµí™”í•˜ë ¤ëŠ” ì˜ì§€ê°€ ë¶„ëª…í•©ë‹ˆë‹¤."
    user_line2 = "ì˜ê²¬ì€ ì‹¤í–‰ ê°€ëŠ¥ì„±ê³¼ ë¦¬ìŠ¤í¬ í†µì œë¥¼ í•¨ê»˜ ê³ ë ¤í•©ë‹ˆë‹¤."
    user_line3 = "ë‹¤ìŒ ë¼ìš´ë“œì—ì„œëŠ” ê·¼ê±°ì˜ ì •ëŸ‰í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤."
    if user_note.strip():
        user_line1 = f"ì‚¬ìš©ìëŠ” '{user_note[:35]}'ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì…ì¥ì„ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."

    next_question = "í˜„ì¬ ì…ì¥ì„ ìœ ì§€í•˜ë©´ì„œë„ ì‹¤íŒ¨ ë¹„ìš©ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•œ ì²« ë²ˆì§¸ ê²€ì¦ ì§€í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"

    return "\n".join(
        [
            "# ğŸ“ ThinkGym ì„¸ì…˜ ë¦¬í¬íŠ¸",
            "",
            "## 1. ì˜¤ëŠ˜ì˜ ì§ˆë¬¸",
            topic,
            "",
            "## 2. ì°¬ë°˜ í•µì‹¬ ìš”ì•½",
            "- **ì°¬ì„±:**",
            f"  1) {split_sentences(pro_text)[0]}",
            f"  2) {split_sentences(pro_text)[1]}",
            f"  3) {split_sentences(pro_text)[2]}",
            "- **ë°˜ëŒ€:**",
            f"  1) {split_sentences(con_text)[0]}",
            f"  2) {split_sentences(con_text)[1]}",
            f"  3) {split_sentences(con_text)[2]}",
            "",
            "## 3. ì‚¬ìš©ìì˜ ì…ì¥",
            user_line1,
            user_line2,
            user_line3,
            "",
            "## 4. ë…¼ë¦¬ êµ¬ì¡° ê°œì„  í¬ì¸íŠ¸",
            f"- {assumption_point}",
            f"- {counter_point}",
            f"- {missing_point}",
            "",
            "## 5. ë‹¤ìŒ ë¼ìš´ë“œ ì¶”ì²œ ì§ˆë¬¸",
            next_question,
        ]
    )


def build_full_prompt(system_text: str, user_text: str, variables: Dict[str, str]) -> str:
    return (
        "[SYSTEM]\n"
        + render_template(system_text, variables)
        + "\n\n[USER]\n"
        + render_template(user_text, variables)
    )


def run_agent(kind: str, variables: Dict[str, str], mock_mode: bool) -> str:
    if mock_mode:
        if kind == "pro":
            return mock_pro(variables["topic"], variables.get("user_note", ""))
        if kind == "con":
            return mock_con(variables["topic"], variables["pro_statement"])
        if kind == "structure":
            return mock_structure(variables["topic"], variables["debate_transcript"], variables["user_note"])
        if kind == "summary":
            structure = json.loads(variables["structure_feedback"])
            return mock_summary(
                variables["topic"],
                variables["pro_statement"],
                variables["con_statement"],
                variables["user_note"],
                structure,
            )
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” kind: {kind}")

    raise RuntimeError("MVPëŠ” í˜„ì¬ --mock ëª¨ë“œë§Œ ì§€ì›í•©ë‹ˆë‹¤. ì‹¤ì œ ëª¨ë¸ ì—°ë™ì€ í›„ì† ë‹¨ê³„ì—ì„œ ì—°ê²°í•˜ì„¸ìš”.")


def generate_with_retry(kind: str, variables: Dict[str, str], mock_mode: bool, max_retries: int = 2):
    errors = []
    for _ in range(max_retries + 1):
        text = run_agent(kind, variables, mock_mode)
        try:
            if kind == "pro":
                ensure_three_sentences(text, "Pro")
                return text
            if kind == "con":
                ensure_three_sentences(text, "Con")
                validate_con_first_sentence(text, variables["pro_statement"])
                validate_con_topic_relevance(text, variables["topic"])
                return text
            if kind == "structure":
                parsed = parse_structure_json(text, variables["user_note"])
                return parsed
            if kind == "summary":
                validate_summary_report(text)
                return text
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” kind: {kind}")
        except Exception as exc:  # pylint: disable=broad-except
            errors.append(str(exc))

    raise RuntimeError(f"{kind} ìƒì„± ì‹¤íŒ¨: {' | '.join(errors)}")


def pick_user_note(round_no: int, notes: List[str], interactive: bool) -> str:
    if round_no - 1 < len(notes):
        return notes[round_no - 1]
    if interactive:
        return input(f"\n[Round {round_no}] ì‚¬ìš©ì ìƒê° ì…ë ¥: ").strip()
    return ""


def extract_next_question(summary_report: str, fallback_topic: str) -> str:
    section = extract_section(summary_report, "## 5. ë‹¤ìŒ ë¼ìš´ë“œ ì¶”ì²œ ì§ˆë¬¸", "")
    lines = [line.strip() for line in section.splitlines() if line.strip()]
    if not lines:
        return fallback_topic
    return lines[0]


def run_session(topic: str, rounds: int, notes: List[str], mock_mode: bool, interactive: bool) -> List[RoundResult]:
    results: List[RoundResult] = []
    current_topic = topic
    previous_note = ""

    for round_no in range(1, rounds + 1):
        pro_statement = generate_with_retry(
            "pro",
            {"topic": current_topic, "user_note": previous_note},
            mock_mode,
        )

        con_statement = generate_with_retry(
            "con",
            {"topic": current_topic, "pro_statement": pro_statement},
            mock_mode,
        )

        debate_transcript = make_debate_transcript(pro_statement, con_statement)
        user_note = pick_user_note(round_no, notes, interactive)

        structure_feedback = generate_with_retry(
            "structure",
            {
                "topic": current_topic,
                "debate_transcript": debate_transcript,
                "user_note": user_note,
            },
            mock_mode,
        )

        summary_report = generate_with_retry(
            "summary",
            {
                "topic": current_topic,
                "debate_transcript": debate_transcript,
                "user_note": user_note,
                "structure_feedback": json.dumps(structure_feedback, ensure_ascii=False),
                "pro_statement": pro_statement,
                "con_statement": con_statement,
            },
            mock_mode,
        )

        next_question = extract_next_question(summary_report, current_topic)

        results.append(
            RoundResult(
                round_no=round_no,
                topic=current_topic,
                pro_statement=pro_statement,
                con_statement=con_statement,
                user_note=user_note,
                structure_feedback=structure_feedback,
                summary_report=summary_report,
                next_question=next_question,
            )
        )

        current_topic = next_question
        previous_note = user_note

    return results


def print_round_output(result: RoundResult) -> None:
    print(f"\n===== Round {result.round_no} =====")
    print(f"ì§ˆë¬¸: {result.topic}")
    print(f"\n[ì°¬ì„±]\n{result.pro_statement}")
    print(f"\n[ë°˜ëŒ€]\n{result.con_statement}")
    print(f"\n[ì‚¬ìš©ì ìƒê°]\n{result.user_note if result.user_note else '(ë¯¸ì…ë ¥)'}")
    print("\n[êµ¬ì¡° í”¼ë“œë°± JSON]")
    print(json.dumps(result.structure_feedback, ensure_ascii=False, indent=2))
    print("\n[ì„¸ì…˜ ë¦¬í¬íŠ¸]")
    print(result.summary_report)
    print(f"\n[ë‹¤ìŒ ë¼ìš´ë“œ ì§ˆë¬¸]\n{result.next_question}")


def verify_prompt_files() -> None:
    required = [
        "pro_agent_system.txt",
        "pro_agent_user.txt",
        "con_agent_system.txt",
        "con_agent_user.txt",
        "structure_agent_system.txt",
        "structure_agent_user.txt",
        "summary_agent_system.txt",
        "summary_agent_user.txt",
    ]
    for filename in required:
        _ = load_prompt(filename)


def main() -> None:
    parser = argparse.ArgumentParser(description="ThinkGym Mini Flow MVP Runner")
    parser.add_argument("--topic", required=True, help="ì²« ë¼ìš´ë“œ ì§ˆë¬¸")
    parser.add_argument("--rounds", type=int, default=2, help="ë¼ìš´ë“œ ìˆ˜ (ê¸°ë³¸ 2)")
    parser.add_argument("--user-note", action="append", default=[], help="ë¼ìš´ë“œë³„ ì‚¬ìš©ì ìƒê° (ìˆœì„œëŒ€ë¡œ ë°˜ë³µ ì…ë ¥)")
    parser.add_argument("--mock", action="store_true", help="ëª¨ì˜ ì‘ë‹µ ëª¨ë“œ")
    parser.add_argument("--non-interactive", action="store_true", help="ì…ë ¥ í”„ë¡¬í”„íŠ¸ ì—†ì´ ì‹¤í–‰")
    args = parser.parse_args()

    if args.rounds < 1:
        raise ValueError("--roundsëŠ” 1 ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    verify_prompt_files()
    results = run_session(
        topic=args.topic,
        rounds=args.rounds,
        notes=args.user_note,
        mock_mode=args.mock,
        interactive=not args.non_interactive,
    )

    for result in results:
        print_round_output(result)


if __name__ == "__main__":
    main()
